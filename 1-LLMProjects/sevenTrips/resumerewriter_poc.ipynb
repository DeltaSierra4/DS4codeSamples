{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvi3KbIzwwe4",
        "outputId": "da5e2f9b-8e59-48ef-d0b3-51f9dbca3f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vincent Yang\n",
            "Email: 60omega@gmail.com\n",
            "Tel: 213-200-0457\n",
            "\n",
            "Summary\n",
            "Senior Data Scientist and NLP/LLM Engineer with 5+ years delivering production machine learning systems, end-to-end data pipelines, and high-impact NLP solutions. Proven record improving model accuracy and latency, deploying features at scale on Azure/AWS/GCP, and leading cross-functional delivery. Expert in Python, LLMs/RAG, MLOps, and unstructured data (text, images, chats); strong communicator who turns complex data into actionable insights.\n",
            "\n",
            "Work Experience\n",
            "Freelance NLP/ML Engineer, Summit Interconnect (Alpine Platform) — May 2024 – Oct 2025\n",
            "• Delivered ITAR classification and information extraction for PCB diagrams via LLMs (GPT/Llama 3/Mistral) with 99% accuracy (precision 0.986, recall 0.998) by orchestrating OCR (ABBYY, Docling), pre/post-processing, and Azure GovCloud APIs.\n",
            "• Integrated Project Echo into Alpine production workflows, cutting diagram-processing latency by 50%; built a RAG chat platform on Azure (Cosmos DB, Azure AI Search, FAISS) that produced 1-year chat summaries in ≤40s vs prior 120s.\n",
            "\n",
            "Freelance NLP/ML Engineer, VM Consultants — Mar 2024 – May 2025\n",
            "• Led a team to build a Llama‑3 RAG smart assistant for EOD technicians, training on 40 GB of text data end-to-end (collection, OCR/cleaning/chunking/embedding/indexing with FAISS) with deployable Raspberry Pi prototypes.\n",
            "• Drove team execution and collaboration (Atlassian, Slack, GitHub), establishing data/experiment pipelines and fine-tuning workflows in Python/PyTorch/HuggingFace/CUDA to enable multi‑step dialog and on‑device inference.\n",
            "\n",
            "LLM Data Annotation Contractor, DataAnnotation — Jan 2024 – Jan 2025; Oct 2025 – Present\n",
            "• Trained and evaluated LLM responses for truthfulness and helpfulness, authoring high‑quality corrections to improve instruction‑following and safety.\n",
            "• Delivered consistent labeling at scale across diverse prompts and domains, strengthening downstream model alignment and evaluation coverage.\n",
            "\n",
            "NLP Data Scientist, PandoLogic (Veritone) — Nov 2022 – Sep 2023\n",
            "• Elevated chatbot FAQ intent detection from 45% to 81% and shipped production PII filtering for resumes by integrating OpenAI GPT features with existing Kore.ai flows on AWS/Azure; instrumented robust JavaScript unit tests.\n",
            "• Built and evaluated NLP prototypes (NLTK, GenSim, spaCy, scikit‑learn, LangChain, pydantic) and deployed services with Flask, Swagger, Kubernetes, accelerating feature delivery from Jupyter proof‑of‑concept to production.\n",
            "\n",
            "Machine Learning Engineer, Thankful.ai (Gladly) — May 2020 – Jul 2022\n",
            "• Improved core NLP models for automated customer support, raising text classification accuracy from 71% to 85% and NER F0.5 from 0.7 to 0.8; performed statistical analyses on performance and ticket traffic to guide roadmap.\n",
            "• Shipped ML features (language detection, keyword extraction, rule‑based dependency matching, decision trees, knowledge‑base scrapers) on GCP using Docker, spaCy, transformers, scikit‑learn, and SQL.\n",
            "\n",
            "Machine Learning Intern, Thankful.ai (Gladly) — May 2019 – Aug 2019\n",
            "• Migrated model training from fastText to spaCy, boosting baseline accuracy from 65% to 71% and modernizing the NLP stack.\n",
            "• Implemented sentiment detection for messages and clustered frequent keywords to surface actionable themes for the chatbot.\n",
            "\n",
            "Skills\n",
            "• Programming: Python, Go, JavaScript, SQL\n",
            "• ML/NLP: HuggingFace, PyTorch, spaCy, scikit-learn, NLTK, GenSim, transformers, pandas, matplotlib\n",
            "• LLMs/RAG: GPT, Llama 3, Mistral, LangChain, FAISS\n",
            "• Cloud/MLOps: Microsoft Azure (incl. GovCloud), AWS, GCP, Docker, Kubernetes, Flask, Swagger, CUDA, Jupyter\n",
            "• Data/DB: PostgreSQL, MySQL, Azure Cosmos DB\n",
            "• Collaboration: Git, Atlassian, Slack\n",
            "• OS: Windows, Ubuntu 22.04\n",
            "• Languages: Korean (native), Japanese (intermediate)\n",
            "\n",
            "Portfolio\n",
            "• Code samples: https://github.com/DeltaSierra4/DS4codeSamples\n",
            "• Social Media Analytics Kit (SMAK): https://github.com/DeltaSierra4/SMAK\n",
            "\n",
            "Certification\n",
            "• AI Engineer for Developers Associate, DataCamp — Oct 2025\n",
            "  https://www.datacamp.com/certificate/AIEDA0018339222215\n",
            "\n",
            "Education\n",
            "• MS, Computer Science (Scientists and Engineers), University of Southern California — May 2020\n",
            "  Relevant coursework: Programming Systems Design, Linear Algebra & Statistics, Machine Learning, Database Systems, Introduction to AI, Natural Language Processing\n",
            "• MS, Organic Chemistry, University of Illinois Urbana–Champaign — May 2016\n",
            "• BA, Chemistry, Northwestern University — Jun 2014\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\"\"YOUR API KEY\"\"\")\n",
        "\n",
        "position = \"<TYPE IN YOUR JOB POSITION>\"\n",
        "\n",
        "run_basic = False  # set to True if you only want to run basic revision (takes priority over comprehensive & standard)\n",
        "run_comprehensive = False  # set to True if you want to run comprehensive revision\n",
        "resume_combiner = False  # set to True if you want to run all three revisions and combine into a single resume\n",
        "\n",
        "userinput_resume = \"\"\"\n",
        "  User resume:```\n",
        "<COPY PASTE YOUR RESUME (IN TEXT FORMAT), LINKEDIN EXPERIENCE, OR ANY OTHER RELEVANT JOB EXPERIENCES TO THE POSITION THAT YOU'RE APPLYING TO>\n",
        "```\n",
        "  --------------------------------------------------------------------------------------------------------\n",
        "  Job posting:'''\n",
        "<COPY PASTE THE JOB POSTING (IN TEXT FORMAT) HERE>\n",
        "  '''\"\"\"\n",
        "\n",
        "def run_basic(client, position, userinput):\n",
        "  system = f\"\"\"\n",
        "  Rewrite my resume for the role of {position}. My resume is delimited by three backticks, and the Job posting is delimited by three single quotation marks.\n",
        "  Follow the following rules:\n",
        "  1. DO NOT MAKE UP EXPERIENCE THAT IS NOT INCLUDED IN THE ORIGINAL USER RESUME.\n",
        "  2. Do not use markdown formatting anywhere.\n",
        "  3. Each job experience must have exactly two bullet points, each bullet point must be relevant to the job position.\n",
        "  4. Use confident, achievement-focused language.\n",
        "  5. Quantify results wherever possible (numbers, %, impact)\n",
        "  6. Remove weak or generic phrases.\n",
        "  7. Match the tone of modern tech/startup resumes.\n",
        "  \"\"\"\n",
        "\n",
        "  response = client.responses.create(\n",
        "      model=\"gpt-5\",\n",
        "      reasoning={\"effort\": \"low\"},\n",
        "      instructions=system,\n",
        "      input=userinput\n",
        "  )\n",
        "\n",
        "  print(response.output_text + \"\\n\\n\\n\" + \"*\" * 80)\n",
        "  return response.output_text\n",
        "\n",
        "\n",
        "def run_standard(client, position, userinput):\n",
        "  system = f\"\"\"\n",
        "You are an expert recruiter and resume writer. You are hiring candidates for the role of {position}, and today you have been approached by an applicant\n",
        "who is asking for your expertise in resumes to match what you actually scan for in 10 seconds.\n",
        "\n",
        "My resume is delimited by three backticks, and the Job posting is delimited by three single quotation marks.\n",
        "Follow the following rules:\n",
        "\n",
        "1. DO NOT MAKE UP EXPERIENCE THAT IS NOT INCLUDED IN THE ORIGINAL USER RESUME.\n",
        "2. Rewrite my experience using numbers, impact, and outcomes. Remove responsibilities. Keep only results.\n",
        "3. Each job experience must have exactly two bullet points, each bullet point must be relevant to the job position.\n",
        "4. Use confident, achievement-focused language.\n",
        "5. Quantify results wherever possible (numbers, %, impact)\n",
        "6. Remove weak or generic phrases.\n",
        "7. Match the tone of modern tech/startup resumes.\n",
        "8. Optimize my resume for ATS keywords for this job description without sounding robotic.”\n",
        "9. Do not use markdown formatting anywhere.\n",
        "10. Cut my resume down to one page while increasing clarity and relevance.\"\"\"\n",
        "\n",
        "  response = client.responses.create(\n",
        "      model=\"gpt-5\",\n",
        "      reasoning={\"effort\": \"low\"},\n",
        "      instructions=system,\n",
        "      input=userinput\n",
        "  )\n",
        "\n",
        "  print(response.output_text + \"\\n\\n\\n\" + \"*\" * 80)\n",
        "  return response.output_text\n",
        "\n",
        "\n",
        "def run_comprehensive():\n",
        "  system = f\"\"\"\n",
        "You are an expert recruiter and resume writer. Help me improve my resume for {position} so it clearly reflects my real experience, sounds like me, and positions me strongly for the roles I’m targeting, increasing my chances of landing interviews.\n",
        "\n",
        "NON-NEGOTIABLE RULES:\n",
        "1. Do not invent, exaggerate, or assume anything (experience, metrics, employers, titles, tools, certifications, dates).\n",
        "2. If information is missing or unclear, ask me before writing.\n",
        "3. Keep my voice human and confident. No corporate fluff.\n",
        "4. Do not copy wording from job postings. Translate my real experience into relevant language.\n",
        "5. Optimize for humans and ATS: clear structure, clean formatting, keyword alignment without stuffing.\n",
        "\n",
        "{userinput}\n",
        "\n",
        "STEP 1: After reviewing everything, summarize:\n",
        "* The top 8–12 skills/keywords across the postings\n",
        "* The 3–5 outcomes the hiring manager likely cares most about\n",
        "* The biggest gaps or weaknesses in my resume for these roles\n",
        "\n",
        "STEP 2: Deliver the following:\n",
        "A) A tailored, ATS-friendly resume (no tables, no columns) including:\n",
        "  - A strong headline and 2-line summary\n",
        "  - Core Skills under each relevant job (10–14 max)\n",
        "  - Experience bullets written as: Action + Scope + Outcome\n",
        "  - Tight bullets (1–2 lines), most relevant first\n",
        "B) A change log explaining what you changed and why\n",
        "C) A truth check list of anything that still needs my confirmation\n",
        "\n",
        "FORMATTING\n",
        "* Use standard headings only: Summary, Core Skills, Experience, Education, Certifications\n",
        "* Present tense for current roles; past tense for previous roles\n",
        "* Use strong verbs and specific outcomes\n",
        "* No buzzwords, clichés, graphics, icons, or heavy design\n",
        "\"\"\"\n",
        "  response = client.responses.create(\n",
        "      model=\"gpt-5\",\n",
        "      reasoning={\"effort\": \"low\"},\n",
        "      instructions=system,\n",
        "      input=userinput\n",
        "  )\n",
        "\n",
        "  print(response.output_text + \"\\n\\n\\n\" + \"*\" * 80)\n",
        "  return response.output_text\n",
        "\n",
        "\n",
        "def combine_resumes(client, position, resumes):\n",
        "  system = f\"\"\"\n",
        "You are an expert resume writer. Today your job is to look over three resumes written for the same position of {position} and combine them together to a single resume for the position.\n",
        "Follow the following rules:\n",
        "\n",
        "1. DO NOT MAKE UP EXPERIENCE THAT IS NOT INCLUDED IN THE ORIGINAL USER RESUME.\n",
        "2. Each job experience must have exactly two bullet points, each bullet point must be relevant to the job position.\n",
        "3. Use confident, achievement-focused language and remove weak or generic phrases. Match the tone of modern tech/startup resumes.\n",
        "4. Optimize the resume for ATS keywords for this job description without sounding robotic.\n",
        "5. Do not use markdown formatting anywhere.\n",
        "6. Cut the resume down to one page while increasing clarity and relevance.\"\"\"\n",
        "\n",
        "  input_array = [\n",
        "          {\n",
        "              \"role\": \"developer\",\n",
        "              \"content\": system\n",
        "          }\n",
        "  ]\n",
        "  for resume in resumes:\n",
        "    input_array.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": resume\n",
        "    })\n",
        "\n",
        "\n",
        "  response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    input=input_array\n",
        "  )\n",
        "\n",
        "  print(response.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if resume_combiner:\n",
        "  combine_resumes(client, position, [run_old(client, position, userinput_resume), run_new_alternate(client, position, userinput_resume), run_new(client, position, userinput_resume)])\n",
        "elif run_basic:\n",
        "  run_basic(client, position, userinput_resume)\n",
        "elif run_comprehensive:\n",
        "  run_comprehensive(client, position, userinput_resume)\n",
        "else:\n",
        "  run_standard(client, position, userinput_resume)"
      ],
      "metadata": {
        "id": "C9G-js9bw102"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}