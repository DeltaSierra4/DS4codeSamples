{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvi3KbIzwwe4",
        "outputId": "da5e2f9b-8e59-48ef-d0b3-51f9dbca3f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vincent Yang\n",
            "Email: 60omega@gmail.com\n",
            "Tel: 213-200-0457\n",
            "\n",
            "Summary\n",
            "Senior Data Scientist and NLP/LLM Engineer with 5+ years delivering production machine learning systems, end-to-end data pipelines, and high-impact NLP solutions. Proven record improving model accuracy and latency, deploying features at scale on Azure/AWS/GCP, and leading cross-functional delivery. Expert in Python, LLMs/RAG, MLOps, and unstructured data (text, images, chats); strong communicator who turns complex data into actionable insights.\n",
            "\n",
            "Work Experience\n",
            "Freelance NLP/ML Engineer, Summit Interconnect (Alpine Platform) — May 2024 – Oct 2025\n",
            "• Delivered ITAR classification and information extraction for PCB diagrams via LLMs (GPT/Llama 3/Mistral) with 99% accuracy (precision 0.986, recall 0.998) by orchestrating OCR (ABBYY, Docling), pre/post-processing, and Azure GovCloud APIs.\n",
            "• Integrated Project Echo into Alpine production workflows, cutting diagram-processing latency by 50%; built a RAG chat platform on Azure (Cosmos DB, Azure AI Search, FAISS) that produced 1-year chat summaries in ≤40s vs prior 120s.\n",
            "\n",
            "Freelance NLP/ML Engineer, VM Consultants — Mar 2024 – May 2025\n",
            "• Led a team to build a Llama‑3 RAG smart assistant for EOD technicians, training on 40 GB of text data end-to-end (collection, OCR/cleaning/chunking/embedding/indexing with FAISS) with deployable Raspberry Pi prototypes.\n",
            "• Drove team execution and collaboration (Atlassian, Slack, GitHub), establishing data/experiment pipelines and fine-tuning workflows in Python/PyTorch/HuggingFace/CUDA to enable multi‑step dialog and on‑device inference.\n",
            "\n",
            "LLM Data Annotation Contractor, DataAnnotation — Jan 2024 – Jan 2025; Oct 2025 – Present\n",
            "• Trained and evaluated LLM responses for truthfulness and helpfulness, authoring high‑quality corrections to improve instruction‑following and safety.\n",
            "• Delivered consistent labeling at scale across diverse prompts and domains, strengthening downstream model alignment and evaluation coverage.\n",
            "\n",
            "NLP Data Scientist, PandoLogic (Veritone) — Nov 2022 – Sep 2023\n",
            "• Elevated chatbot FAQ intent detection from 45% to 81% and shipped production PII filtering for resumes by integrating OpenAI GPT features with existing Kore.ai flows on AWS/Azure; instrumented robust JavaScript unit tests.\n",
            "• Built and evaluated NLP prototypes (NLTK, GenSim, spaCy, scikit‑learn, LangChain, pydantic) and deployed services with Flask, Swagger, Kubernetes, accelerating feature delivery from Jupyter proof‑of‑concept to production.\n",
            "\n",
            "Machine Learning Engineer, Thankful.ai (Gladly) — May 2020 – Jul 2022\n",
            "• Improved core NLP models for automated customer support, raising text classification accuracy from 71% to 85% and NER F0.5 from 0.7 to 0.8; performed statistical analyses on performance and ticket traffic to guide roadmap.\n",
            "• Shipped ML features (language detection, keyword extraction, rule‑based dependency matching, decision trees, knowledge‑base scrapers) on GCP using Docker, spaCy, transformers, scikit‑learn, and SQL.\n",
            "\n",
            "Machine Learning Intern, Thankful.ai (Gladly) — May 2019 – Aug 2019\n",
            "• Migrated model training from fastText to spaCy, boosting baseline accuracy from 65% to 71% and modernizing the NLP stack.\n",
            "• Implemented sentiment detection for messages and clustered frequent keywords to surface actionable themes for the chatbot.\n",
            "\n",
            "Skills\n",
            "• Programming: Python, Go, JavaScript, SQL\n",
            "• ML/NLP: HuggingFace, PyTorch, spaCy, scikit-learn, NLTK, GenSim, transformers, pandas, matplotlib\n",
            "• LLMs/RAG: GPT, Llama 3, Mistral, LangChain, FAISS\n",
            "• Cloud/MLOps: Microsoft Azure (incl. GovCloud), AWS, GCP, Docker, Kubernetes, Flask, Swagger, CUDA, Jupyter\n",
            "• Data/DB: PostgreSQL, MySQL, Azure Cosmos DB\n",
            "• Collaboration: Git, Atlassian, Slack\n",
            "• OS: Windows, Ubuntu 22.04\n",
            "• Languages: Korean (native), Japanese (intermediate)\n",
            "\n",
            "Portfolio\n",
            "• Code samples: https://github.com/DeltaSierra4/DS4codeSamples\n",
            "• Social Media Analytics Kit (SMAK): https://github.com/DeltaSierra4/SMAK\n",
            "\n",
            "Certification\n",
            "• AI Engineer for Developers Associate, DataCamp — Oct 2025\n",
            "  https://www.datacamp.com/certificate/AIEDA0018339222215\n",
            "\n",
            "Education\n",
            "• MS, Computer Science (Scientists and Engineers), University of Southern California — May 2020\n",
            "  Relevant coursework: Programming Systems Design, Linear Algebra & Statistics, Machine Learning, Database Systems, Introduction to AI, Natural Language Processing\n",
            "• MS, Organic Chemistry, University of Illinois Urbana–Champaign — May 2016\n",
            "• BA, Chemistry, Northwestern University — Jun 2014\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\"\"YOUR API KEY\"\"\")\n",
        "\n",
        "position = \"Senior Data Scientist\"\n",
        "\n",
        "old_ver = False\n",
        "run_alter = False\n",
        "resume_combiner = False\n",
        "\n",
        "userinput_resume = \"\"\"\n",
        "  User resume:```\n",
        "  Vincent Yang\n",
        "  Email: 60omega@gmail.com\n",
        "  Tel. 213-200-0457\n",
        "\n",
        "\n",
        "\n",
        "  Summary\n",
        "  Highly skilled NLP Engineer/Prompt Engineer with 5 years of experience in building intelligent NLP systems featuring LLMs. Proficient in Python and Microsoft Azure cloud environments. Expertise in LLMs, RAG architecture, prompt engineering, and building conversational agents. Experience in startup environments with excellent communication skills and ability to gather insight from big data.\n",
        "\n",
        "  Work Experience\n",
        "  •\tFreelancer, Multiple clients∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙Jan 2024 – Present\n",
        "  o\tSummit Interconnect∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙May 2024 – Oct 2025\n",
        "  o\tTechnologies used: Python, Microsoft Azure GovCloud, OpenAI, GPT, HuggingFace, Llama 3, Mistral, Claude\n",
        "  o\tLed Project Echo, a project to utilize LLMs for ITAR classification and information extraction from Precision Circuit Board diagrams, as part of Summit’s Alpine Software, a platform to streamline production of PCB.\n",
        "  •\tEngaged in extensive prompt engineering with various LLMs, including GPT, Llama 3, and Mistral. Accuracy of classification reached 99%, with 0.986 precision and 0.998 recall.\n",
        "  o\tDeveloped and maintained an end-to-end pipeline hosted on Microsoft Azure GovCloud consisting of OCR softwares and frameworks such as ABBYY and Docling, pre-/post-processing scripts, and API endpoints for PCB diagram classification system.\n",
        "  o\tProject Echo was successfully integrated into Alpine, Summit’s platform for PCB diagram quotes, resulting in 50% reduction of latency in processing diagrams resulting from switching from manual workflow to LLM-based automation.\n",
        "  o\tBuilt a contextual chat platform that allows users to obtain summaries of chats, extract order information, with RAG architecture hosted on Azure GovCloud with Azure Cosmos DB and Azure AI Search.\n",
        "  •\tExperimented with various LLM options hosted on Azure, including GPT, Mistral, and Claude. Datasets were managed with pandas, indexed with FAISS, and hosted on Azure Cosmos.\n",
        "  •\tChat summarizer provided chat summaries in 40 seconds at most with 1 year worth of chat messages, compared to 120 seconds used by Slack’s AI summarizer that was in use previously.\n",
        "  o\tVM Consultants∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙Mar 2024 – May 2025\n",
        "  o\tTechnologies used: Python, Pytorch, HuggingFace, CUDA, spaCy, GPT, Llama 3, FAISS, Raspberry Pi\n",
        "  o\tLed a team of engineers to develop a smart assistant for EOD technicians built with Llama-3-based model with RAG system.\n",
        "  o\tTrained RAG models on a large text dataset (40 GB) capable of multi-step dialogue with end users, starting from data collection to pre-training and fine-tuning models.\n",
        "  o\tPre-processing steps (OCR/text-scanning, text-cleaning, chunking, embedding, and indexing with FAISS) for dataset used by RAG model.\n",
        "  o\tSet up collaboration environment (Atlassian, Slack channels, Github) for team to work on final product together.\n",
        "  o\tSuccessfully built prototypes on Raspberry Pi to be tested by end users.\n",
        "  o\tDataAnnotation∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙Jan 2024 – Jan 2025, Oct 2025 – Present\n",
        "  o\tAs a side gig, I engage in model training to analyze and evaluate sets of responses from a large language model to respond with truthfulness and helpfulness. Writing/correcting model responses where it needs correction.\n",
        "\n",
        "  •\tNLP Data Scientist, PandoLogic (Now merged with Veritone) ∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙Nov 2022 – Sep 2023\n",
        "  o\tTechnologies used: Python, Javascript, spaCy, NLTK, GenSim, scikit-learn, GPT-3.5, Azure, LangChain, AWS, Neo4j, Jupyter\n",
        "  o\tWorked on company’s chatbot system based on Kore.ai built for job recruiting.\n",
        "  o\tImproved the NLP model of the chatbot to boost detection of FAQ intent from 45% to 81%\n",
        "  o\tDesigned and implemented robust Javascript unit tests to ensure that chatbot scripts worked as ensured.\n",
        "  o\tEngaged in extensive prompt engineering using iterative prompting and implemented new features for chatbot including resume filter, parser, summarizer, PII extractor, and slot-filling by integration with OpenAI GPT models.\n",
        "  o\tProof of concept was experimented with NLTK and GenSim, demonstrated with LangChain and pydantic. Hosted new features with Flask, Swagger, Kubernetes, on a server hosted on AWS. Features were demonstrated with Jupyter.\n",
        "  o\tFeature was successfully deployed on production to sanitize customer data by filtering out PII from user resumes.\n",
        "\n",
        "  •\tMachine Learning Engineer, Thankful.ai (Now merged with Gladly) ∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙May 2020 – July 2022\n",
        "  o\tTechnologies used: Python, spaCy, transformer models, CUDA, GoLang, Google Cloud Platform, Docker, scikit-learn, SQL, PostGRES, pandas, matplotlib, Jupyter\n",
        "  o\tBuilt and improved NLP models for Thankful’s customer service platform specializing in automating customer service tickets, hosted on Google Cloud Platform.\n",
        "  Work Experience cont’d\n",
        "  o\tBoosted accuracy from 71% to 85% for text classifier and from 0.7 to 0.8 in F-0.5 score for Named Entity Recognition model.\n",
        "  o\tPerformed statistical analysis on model performance data, customer ticket traffic, and gathered relevant business intelligence.\n",
        "  o\tBuilt, experimented with, and debugged prototypes of new features to be integrated to Thankful’s chatbot and platform.\n",
        "  o\tNew features include: Language detection, keyword extraction, rule-based dependency matching, decision trees for product/FAQ suggestions, and knowledge base scrapers. Features were demonstrated with Jupyter.\n",
        "\n",
        "  •\tMachine Learning Intern, Thankful.ai (Now merged with Gladly) ∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙May 2019 – Aug 2019\n",
        "  o\tMigrated NLP model training from fasttext to Spacy; improved baseline accuracy from 65% to 71%.\n",
        "  o\tImplemented sentiment detection in text messages for chatbot and perform clustering analysis for frequently occurring keywords.\n",
        "\n",
        "  Skills\n",
        "\n",
        "  •\tOperating Systems: Windows, Linux Ubuntu 22.04\n",
        "  •\tProgramming Languages: Python, GoLang, Javascript\n",
        "  •\tCloud Environments: AWS, Microsoft Azure, GCP\n",
        "  •\tMachine Learning: HuggingFace, PyTorch, spaCy, scikit-learn, NLTK, GenSim\n",
        "  •\tRAG/LLMs: GPT, Llama 3, Mistral, LangChain\n",
        "  •\tDatabase: MySQL, PostgreSQL\n",
        "  •\tCollaboration tools: Git, Jupyter, Atlassian\n",
        "  •\tMiscellaneous: Flask, Swagger, CUDA, Google Colab\n",
        "  •\tOther languages: Korean (native), Japanese (intermediate)\n",
        "\n",
        "\n",
        "  Portfolio\n",
        "  •\tMy code sample repository: https://github.com/DeltaSierra4/DS4codeSamples\n",
        "  •\tSocial Media Analytics Kit (SMAK): https://github.com/DeltaSierra4/SMAK\n",
        "\n",
        "  Certification\n",
        "  •\tAI Engineer for Developers Associate Certificate, Datacamp ∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙Oct 2025\n",
        "  o\tLink: https://www.datacamp.com/certificate/AIEDA0018339222215\n",
        "\n",
        "  Education\n",
        "  •\tMS, Computer Science (Scientists and Engineers), University of Southern California∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙Graduated May 2020\n",
        "  o\tRelevant coursework: Intro to Programming Systems Design, Linear Algebra & Statistics, Machine Learning, Database Systems, Introduction to Artificial Intelligence, Natural Language Processing\n",
        "  •\tMS, Organic Chemistry, University of Illinois Urbana Champaign∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙Graduated May 2016\n",
        "  •\tBA, Chemistry, Northwestern University∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙∙Graduated Jun 2014```\n",
        "  --------------------------------------------------------------------------------------------------------\n",
        "  Job posting:'''\n",
        "\n",
        "  About Nexon\n",
        "\n",
        "  Nexon America is a branch of Nexon Co., Ltd., a global video game publisher and leading developer of online virtual worlds for PCs, consoles, and mobile devices. Nexon proudly offers celebrated franchises like MapleStory and Mabinogi that have been enjoyed by millions of players for over two decades. When we founded our Nexon America branch in 2006, we made it our goal to bring those unique games to western players using a player-first approach. We achieve that goal by applying our team’s outstanding free-to-play expertise and live game support to every decision, every day.\n",
        "\n",
        "  But we’re committed to more than our games! Here at Nexon America, we’re all about open communication, diversity, mutual respect, and collaboration, so we can bring out the best in each other. Nexies find support, friendship, and career growth all in one place! And because we know a healthy work-life balance is the key to happiness, Nexies also enjoy flexible hours, a hybrid work model, and extra perks like food trucks, happy hours, and team events. It’s why we’ve earned the Great Place to Work certification for 5 years running!\n",
        "\n",
        "  We’re looking to expand our team with passionate individuals who want to learn, play, and grow with us. Ready for a new challenge?\n",
        "\n",
        "  Summary of Position\n",
        "\n",
        "  Nexon America is looking for a talented Sr. Data Scientist to help Nexon’s game business through data-driven insights and solve critical business problems by developing advanced machine learning algorithms. The Sr. Data Scientist is passionate about games, analytics, and applying advanced data science techniques to improve player experience, retention, and monetization. The Sr. Data Scientist collaborates with our Data teams, Business teams, Security team, and other stakeholders to implement data science models into live production systems. The Sr. Data Scientist brings fresh perspectives to inform decision-making toward better player experience by translating player voice into insights.\n",
        "\n",
        "  We are currently working in the office 2-3x a week in a hybrid work model.\n",
        "\n",
        "  Job Responsibilities\n",
        "\n",
        "      Apply your expertise in quantitative analysis, data visualization and data mining to tell the story behind numbers and find relevant insights for partners and leadership\n",
        "      Build and evaluate the ML models and statistical methods to provide Insight & Recommendation and solve the business problems\n",
        "      Establish scalable, automated processes for large scale data extraction, model development, model validation, model deployment, and its monitoring\n",
        "      Research and develop state-of-the-art machine learning, data mining, statistical modeling solutions, and language models to understand game business and key business behaviors, such as player acquisition, retention, and monetization\n",
        "      Maintain clear and comprehensive documentation of the models and analysis results, and present the results to the stakeholders clearly and effectively\n",
        "      Work closely with other data scientists, data analysts, data engineers, and other stakeholders to understand project requirements, provide valuable insights, and advanced solutions.\n",
        "      Mentor other engineers and scientists and contribute to their growth by providing guidance and advice.\n",
        "      Lead the improvement of the team’s process.\n",
        "      Other duties as assigned\n",
        "\n",
        "  Work Experience\n",
        "\n",
        "      5+ years of proven professional working experience as a Data Scientist or related field (Advanced degrees may substitute for part of the required experience.)\n",
        "\n",
        "  Education, Professional Training, Technical Training or Certification\n",
        "\n",
        "      BS (MS/PhD Preferred) in quantitative discipline (e.g. Computer Science, Statistics, Applied Mathematics, or a related field)\n",
        "\n",
        "  Knowledge/Skills\n",
        "\n",
        "      Expertise in machine learning and statistical analysis approaches such as classification, clustering, regression, statistical inference, collaborative filtering, natural language processing, experimental design, social networking analysis, etc.\n",
        "      Experience managing advanced analytics projects which solve complex analytical problems using data exploration and analysis skills\n",
        "      Experience working with unstructured data (e.g., text, logs, JSON, images)\n",
        "      Expertise in evaluating, automating, deploying, and monitoring models in production systems\n",
        "      A true passion for understanding customer behavior on-platform and in-game\n",
        "      Expert analytical and problem-solving skills, plus the ability to innovate and work with strong initiative\n",
        "      Strong skills in statistical methods (e.g. hypothesis testing, time series modeling)\n",
        "      Strong SQL skills and strong Python skills; familiarity with Jupyter Notebook\n",
        "      Familiar with modern data platforms, and cloud systems (e.g. Snowflake, AWS)\n",
        "      Professional large language models and MLOps experience is a plus.\n",
        "      Online gaming experience is a BIG PLUS!\n",
        "\n",
        "  Management has the right to add or change duties and job requirements at any time.\n",
        "  '''\"\"\"\n",
        "\n",
        "def run_old(client, position, userinput):\n",
        "  system = f\"\"\"\n",
        "  Rewrite my resume for the role of {position}. My resume is delimited by three backticks, and the Job posting is delimited by three single quotation marks.\n",
        "  Follow the following rules:\n",
        "  1. DO NOT MAKE UP EXPERIENCE THAT IS NOT INCLUDED IN THE ORIGINAL USER RESUME.\n",
        "  2. Do not use markdown formatting anywhere.\n",
        "  3. Each job experience must have exactly two bullet points, each bullet point must be relevant to the job position.\n",
        "  4. Use confident, achievement-focused language.\n",
        "  5. Quantify results wherever possible (numbers, %, impact)\n",
        "  6. Remove weak or generic phrases.\n",
        "  7. Match the tone of modern tech/startup resumes.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "  response = client.responses.create(\n",
        "      model=\"gpt-5\",\n",
        "      reasoning={\"effort\": \"low\"},\n",
        "      instructions=system,\n",
        "      input=userinput\n",
        "  )\n",
        "\n",
        "  print(response.output_text + \"\\n\\n\\n\" + \"*\" * 80)\n",
        "  return response.output_text\n",
        "\n",
        "\n",
        "def run_new():\n",
        "  system = f\"\"\"\n",
        "You are an expert recruiter and resume writer. Help me improve my resume for {position} so it clearly reflects my real experience, sounds like me, and positions me strongly for the roles I’m targeting, increasing my chances of landing interviews.\n",
        "\n",
        "NON-NEGOTIABLE RULES:\n",
        "1. Do not invent, exaggerate, or assume anything (experience, metrics, employers, titles, tools, certifications, dates).\n",
        "2. If information is missing or unclear, ask me before writing.\n",
        "3. Keep my voice human and confident. No corporate fluff.\n",
        "4. Do not copy wording from job postings. Translate my real experience into relevant language.\n",
        "5. Optimize for humans and ATS: clear structure, clean formatting, keyword alignment without stuffing.\n",
        "\n",
        "{userinput}\n",
        "\n",
        "STEP 1: After reviewing everything, summarize:\n",
        "* The top 8–12 skills/keywords across the postings\n",
        "* The 3–5 outcomes the hiring manager likely cares most about\n",
        "* The biggest gaps or weaknesses in my resume for these roles\n",
        "\n",
        "STEP 2: Deliver the following:\n",
        "A) A tailored, ATS-friendly resume (no tables, no columns) including:\n",
        "  - A strong headline and 2-line summary\n",
        "  - Core Skills under each relevant job (10–14 max)\n",
        "  - Experience bullets written as: Action + Scope + Outcome\n",
        "  - Tight bullets (1–2 lines), most relevant first\n",
        "B) A change log explaining what you changed and why\n",
        "C) A truth check list of anything that still needs my confirmation\n",
        "\n",
        "FORMATTING\n",
        "* Use standard headings only: Summary, Core Skills, Experience, Education, Certifications\n",
        "* Present tense for current roles; past tense for previous roles\n",
        "* Use strong verbs and specific outcomes\n",
        "* No buzzwords, clichés, graphics, icons, or heavy design\n",
        "\"\"\"\n",
        "  response = client.responses.create(\n",
        "      model=\"gpt-5\",\n",
        "      reasoning={\"effort\": \"low\"},\n",
        "      instructions=system,\n",
        "      input=userinput\n",
        "  )\n",
        "\n",
        "  print(response.output_text + \"\\n\\n\\n\" + \"*\" * 80)\n",
        "  return response.output_text\n",
        "\n",
        "\n",
        "\n",
        "def run_new_alternate(client, position, userinput):\n",
        "  system = f\"\"\"\n",
        "You are an expert recruiter and resume writer. You are hiring candidates for the role of {position}, and today you have been approached by an applicant\n",
        "who is asking for your expertise in resumes to match what you actually scan for in 10 seconds.\n",
        "\n",
        "My resume is delimited by three backticks, and the Job posting is delimited by three single quotation marks.\n",
        "Follow the following rules:\n",
        "\n",
        "1. DO NOT MAKE UP EXPERIENCE THAT IS NOT INCLUDED IN THE ORIGINAL USER RESUME.\n",
        "2. Rewrite my experience using numbers, impact, and outcomes. Remove responsibilities. Keep only results.\n",
        "3. Each job experience must have exactly two bullet points, each bullet point must be relevant to the job position.\n",
        "4. Use confident, achievement-focused language.\n",
        "5. Quantify results wherever possible (numbers, %, impact)\n",
        "6. Remove weak or generic phrases.\n",
        "7. Match the tone of modern tech/startup resumes.\n",
        "8. Optimize my resume for ATS keywords for this job description without sounding robotic.”\n",
        "9. Do not use markdown formatting anywhere.\n",
        "10. Cut my resume down to one page while increasing clarity and relevance.\"\"\"\n",
        "\n",
        "  response = client.responses.create(\n",
        "      model=\"gpt-5\",\n",
        "      reasoning={\"effort\": \"low\"},\n",
        "      instructions=system,\n",
        "      input=userinput\n",
        "  )\n",
        "\n",
        "  print(response.output_text + \"\\n\\n\\n\" + \"*\" * 80)\n",
        "  return response.output_text\n",
        "\n",
        "\n",
        "def combine_resumes(client, position, resumes):\n",
        "  system = f\"\"\"\n",
        "You are an expert resume writer. Today your job is to look over three resumes written for the same position of {position} and combine them together to a single resume for the position.\n",
        "Follow the following rules:\n",
        "\n",
        "1. DO NOT MAKE UP EXPERIENCE THAT IS NOT INCLUDED IN THE ORIGINAL USER RESUME.\n",
        "2. Each job experience must have exactly two bullet points, each bullet point must be relevant to the job position.\n",
        "3. Use confident, achievement-focused language and remove weak or generic phrases. Match the tone of modern tech/startup resumes.\n",
        "4. Optimize the resume for ATS keywords for this job description without sounding robotic.\n",
        "5. Do not use markdown formatting anywhere.\n",
        "6. Cut the resume down to one page while increasing clarity and relevance.\"\"\"\n",
        "\n",
        "  input_array = [\n",
        "          {\n",
        "              \"role\": \"developer\",\n",
        "              \"content\": system\n",
        "          }\n",
        "  ]\n",
        "  for resume in resumes:\n",
        "    input_array.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": resume\n",
        "    })\n",
        "\n",
        "\n",
        "  response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    input=input_array\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if resume_combiner:\n",
        "  combine_resumes(client, position, [run_old(client, position, userinput_resume), run_new_alternate(client, position, userinput_resume), run_new(client, position, userinput_resume)])\n",
        "elif old_ver:\n",
        "  run_old(client, position, userinput_resume)\n",
        "elif run_alter:\n",
        "  run_new_alternate(client, position, userinput_resume)\n",
        "else:\n",
        "  run_new(client, position, userinput_resume)"
      ],
      "metadata": {
        "id": "C9G-js9bw102"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}